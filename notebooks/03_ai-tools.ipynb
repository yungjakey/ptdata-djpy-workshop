{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries for file handling, HTTP requests, and the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import google.generativeai as genai\n",
    "\n",
    "from urllib.parse import urlparse, quote\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Functions and News URLs\n",
    "Define the list of 20 German/European news sources and create helper functions for fetching content and generating filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of 20 German/European news sources\n",
    "NEWS_URLS = [\n",
    "    \"https://www.spiegel.de\",\n",
    "    \"https://www.orf.at\",\n",
    "    \"https://www.faz.net\",\n",
    "    \"https://www.welt.de\",\n",
    "    \"https://www.lemonde.fr\",\n",
    "    \"https://www.lefigaro.fr\",\n",
    "    \"https://www.corriere.it\",\n",
    "    \"https://www.theguardian.com\",\n",
    "    \"https://www.lavanguardia.com\",\n",
    "    \"https://www.euronews.com\",\n",
    "]\n",
    "\n",
    "# Define the output directory for saving fetched content\n",
    "out_dir = \"data/misc/webpgs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_md(url):\n",
    "    encoded_url = quote(url, safe=\"\")\n",
    "    jina_url = f\"https://r.jina.ai/{encoded_url}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(jina_url, timeout=30)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "    except requests.exceptions.Timeout as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def fname(url):\n",
    "    d = urlparse(url).netloc.split(\"www.\")[1]\n",
    "    return f\"{d.replace('/', '_')}.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch and Save News Articles\n",
    "Loop through the news URLs, fetch content for each one, and save the retrieved markdown content to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the news URLs, fetch content for each one, and save the retrieved markdown content to files\n",
    "for url in NEWS_URLS:\n",
    "    fn = f\"{out_dir}/{fname(url)}\"\n",
    "    md = fetch_md(url)  # Fetch markdown content for the URL\n",
    "    if md:  # If content is successfully fetched\n",
    "        print(f\"Saving {fn}...\")\n",
    "        with open(fn, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(md)  # Save the content to a file in the output director"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Saved Articles\n",
    "Read the saved markdown files and load their contents into a dictionary for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {}\n",
    "for filename in os.listdir(out_dir):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(out_dir, filename)\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            file_stem = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "            articles[file_stem] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Gemini Client\n",
    "Set up the Gemini client using API keys from environment variables and configure the model to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining a Google Gemini API Key\n",
    "\n",
    "To use the Gemini API in this notebook, you'll need to obtain an API key:\n",
    "\n",
    "1. **Go to Google AI Studio**: Visit [makersuite.google.com](https://makersuite.google.com/)\n",
    "\n",
    "2. **Sign in with your Google Account**: Create one if needed\n",
    "\n",
    "3. **Get API Key**: \n",
    "   - Click on your profile picture in the top-right corner\n",
    "   - Select \"Get API key\"\n",
    "   - Either create a new key or use an existing one\n",
    "\n",
    "4. **Security Best Practices**:\n",
    "   - Store your key in an environment variable or .env file\n",
    "   - Add .env to your .gitignore file\n",
    "   - Never commit API keys to version control\n",
    "\n",
    "For more information, visit the [Gemini API documentation](https://ai.google.dev/docs/gemini-api/setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = \"sadkal12312asdl0312ejksdfj1023\"\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the API with your key\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Then you can use the API directly\n",
    "model = genai.GenerativeModel(MODEL)  # Replace MODEL with your model name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gemini Query Function\n",
    "Create a function to send prompts to the Gemini API and retrieve responses with appropriate configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_query(prompt):\n",
    "    try:\n",
    "        # The model instance is already created as 'model' variable\n",
    "        response = model.generate_content(\n",
    "            prompt,  # Just pass the prompt directly\n",
    "            generation_config={\n",
    "                \"max_output_tokens\": 500,  # Limit the output tokens\n",
    "                \"temperature\": 0.3,  # Set the temperature for response variability\n",
    "            },\n",
    "        )\n",
    "        # Extract text from the response\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"  # Handle any exceptions and return the error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Different Gemini Queries\n",
    "Run five different types of queries on the collected news data: individual summaries, trend extraction from a specific source, creative summary, overall news trends analysis, and technology/AI coverage analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, content in articles.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(content)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Summarize main headlines for each individual article\n",
    "print(\"=== Query 1: Summaries for individual pages ===\")\n",
    "for name, content in articles.items():\n",
    "    prompt = f\"\"\"The text below was scraped from {name}. Please summarize the main headlines and key news from this ALREADY SCRAPED content:\n",
    "\n",
    "CONTENT:\n",
    "{content[:2000]}\n",
    "\"\"\"\n",
    "    summary = gemini_query(prompt)\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Extract emerging trends from a specific source (e.g., \"spiegel.de\")\n",
    "if \"spiegel.de\" in articles:\n",
    "    prompt = f\"\"\"The text below was already scraped from spiegel.de. Based ONLY on this pre-scraped content, list 3 emerging news trends:\n",
    "\n",
    "CONTENT:\n",
    "{articles[\"spiegel.de\"][:1500]}\n",
    "\"\"\"\n",
    "    print(\"\\n=== Query 2: Emerging trends on spiegel.de ===\")\n",
    "    print(gemini_query(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Provide a creative summary for a specific source (e.g., \"dw.com\")\n",
    "if \"dw.com\" in articles:\n",
    "    prompt = f\"\"\"The text below was already scraped from dw.com. Based ONLY on this pre-scraped content, provide a creative summary of the news:\n",
    "\n",
    "CONTENT:\n",
    "{articles[\"dw.com\"][:1500]}\n",
    "\"\"\"\n",
    "    print(\"\\n=== Query 3: Creative summary for dw.com ===\")\n",
    "    print(gemini_query(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4: Analyze major news trends across all sources\n",
    "full_text = \"\\n\\n---SOURCE SEPARATOR---\\n\\n\".join(articles.values())\n",
    "prompt = f\"\"\"The text below contains ALREADY SCRAPED content from multiple European news sources. Based ONLY on this pre-scraped content, list 5 major news trends and summarize the overall current news landscape:\n",
    "\n",
    "CONTENT:\n",
    "{full_text[:5000]}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Query 4: Overall European news trends ===\")\n",
    "print(gemini_query(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 5: Analyze how technology and AI are covered across all sources\n",
    "prompt = f\"\"\"The text below contains ALREADY SCRAPED content from multiple European news sources. Based ONLY on this pre-scraped content, analyze and summarize how technology and AI are being covered. Highlight any emerging themes or concerns:\n",
    "\n",
    "CONTENT:\n",
    "{full_text[:5000]}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Query 5: Technology and AI coverage analysis ===\")\n",
    "print(gemini_query(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "djpyworkshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
