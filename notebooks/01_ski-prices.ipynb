{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ski Resort Price Analysis\n",
    "\n",
    "This notebook explores ski resort pricing data along with weather information to identify patterns, trends, and correlations. We'll work through loading, cleaning, and analyzing CSV data to extract meaningful insights about how factors like weather and location impact ski resort prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_palette(\"viridis\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with CSV Data\n",
    "\n",
    "### 1.1 Reading and Exploring CSV Data\n",
    "\n",
    "First, we'll load our datasets and perform some initial exploration to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "df_prices = pd.read_csv(\"../data/01_ski-prices/prices.csv\")\n",
    "df_weather = pd.read_csv(\"../data/01_ski-prices/weather.csv\")\n",
    "\n",
    "print(\"Ski Resort Prices - First 5 rows:\")\n",
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the price dataset\n",
    "print(\"Price dataset info:\")\n",
    "df_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of the price data\n",
    "df_prices.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in price data\n",
    "print(\"Missing values in price data:\")\n",
    "df_prices.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the weather data\n",
    "print(\"Weather data - First 5 rows:\")\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the weather dataset\n",
    "print(\"Weather dataset info:\")\n",
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in weather data\n",
    "print(\"Missing values in weather data:\")\n",
    "df_weather.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Distribution Analysis\n",
    "\n",
    "Let's examine the distribution of our key variables before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of temperature and precipitation\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "sns.histplot(df_prices[\"price\"], kde=True)\n",
    "ax[0].set_title(\"Distribution of Ski Resort Prices\")\n",
    "ax[0].set_xlabel(\"Price (€)\")\n",
    "\n",
    "sns.histplot(df_weather[\"temperature\"], kde=True, ax=ax[0])\n",
    "ax[1].set_title(\"Temperature Distribution\")\n",
    "ax[1].set_xlabel(\"Temperature (°C)\")\n",
    "\n",
    "sns.histplot(df_weather[\"precipitation\"], kde=True, ax=ax[1])\n",
    "ax[2].set_title(\"Precipitation Distribution\")\n",
    "ax[2].set_xlabel(\"Precipitation (mm)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Handling Missing Values\n",
    "\n",
    "Now we'll handle missing values in our datasets. For some analyses we'll drop them, while for others (like correlation) we'll handle them more carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaned copies for general analysis (dropping missing values)\n",
    "df_prices_cleaned = df_prices.dropna()\n",
    "df_weather_cleaned = df_weather.dropna()\n",
    "\n",
    "# Create copies for correlation analysis (keeping the original structure)\n",
    "df_prices_for_correlation = df_prices.copy()\n",
    "df_weather_for_correlation = df_weather.copy()\n",
    "\n",
    "# Count records before and after cleaning\n",
    "print(\n",
    "    f\"Price data: {len(df_prices)} rows before cleaning, {len(df_prices_cleaned)} after cleaning\"\n",
    ")\n",
    "print(\n",
    "    f\"Weather data: {len(df_weather)} rows before cleaning, {len(df_weather_cleaned)} after cleaning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Merging Datasets\n",
    "\n",
    "Let's combine our price and weather data to analyze how weather conditions might affect pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on date and region\n",
    "df_merged = df_prices_cleaned.merge(\n",
    "    df_weather_cleaned, on=[\"date\", \"region\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset has {len(df_merged)} rows\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Filtering and Aggregation\n",
    "\n",
    "Let's examine specific regions and calculate aggregated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime format\n",
    "df_merged[\"date\"] = pd.to_datetime(df_merged[\"date\"])\n",
    "\n",
    "# List unique regions\n",
    "print(\"Available regions:\")\n",
    "df_merged[\"region\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for a specific resort\n",
    "kitzbuehl_df = df_merged[df_merged[\"region\"] == \"Kitzbuehl\"]\n",
    "print(f\"Kitzbuehl dataset has {len(kitzbuehl_df)} rows\")\n",
    "kitzbuehl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly average price per region\n",
    "df_monthly = (\n",
    "    df_merged.groupby([df_merged[\"date\"].dt.to_period(\"M\"), \"region\"])[\"price\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert period to string for better display\n",
    "df_monthly[\"date\"] = df_monthly[\"date\"].astype(str)\n",
    "\n",
    "print(\"Monthly average prices by region:\")\n",
    "df_monthly.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price statistics by region\n",
    "region_stats = (\n",
    "    df_merged.groupby(\"region\")[\"price\"]\n",
    "    .agg([\"mean\", \"median\", \"min\", \"max\", \"std\"])\n",
    "    .round(2)\n",
    ")\n",
    "print(\"Price statistics by region:\")\n",
    "region_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Visualizing Trends\n",
    "\n",
    "Let's visualize price trends over time for different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling average to smooth trends\n",
    "df_merged[\"rolling_avg\"] = df_merged.groupby(\"region\")[\"price\"].transform(\n",
    "    lambda x: x.rolling(7, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# Plot the smoothed trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "for region in df_merged[\"region\"].unique():\n",
    "    subset = df_merged[df_merged[\"region\"] == region]\n",
    "    plt.plot(subset[\"date\"], subset[\"rolling_avg\"], label=f\"{region} (7-day avg)\")\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Rolling Avg Price (€)\")\n",
    "plt.title(\"Smoothed Ski Resort Price Trends (7-day Rolling Average)\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Correlation Analysis\n",
    "\n",
    "Let's examine the relationships between price and weather variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on date and region to analyze correlations\n",
    "df_correlation = pd.merge(\n",
    "    df_weather_for_correlation,\n",
    "    df_prices_for_correlation,\n",
    "    on=[\"date\", \"region\"],\n",
    "    how=\"inner\",  # Keep only rows that match in both datasets\n",
    ")\n",
    "\n",
    "# Remove rows with missing values for clean correlation analysis\n",
    "df_correlation = df_correlation.dropna()\n",
    "\n",
    "# Add a day of week column to analyze weekday patterns\n",
    "df_correlation[\"day_of_week\"] = pd.to_datetime(df_correlation[\"date\"]).dt.dayofweek\n",
    "\n",
    "# Create a 2x2 grid of subplots (one row for each relationship, one column for each region)\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 20))\n",
    "fig.suptitle(\"Weather Effects on Ski Prices by Region\", fontsize=20, y=1.01)\n",
    "\n",
    "regions = df_correlation[\"region\"].unique()\n",
    "\n",
    "# Temperature vs Price - one plot per region\n",
    "for i, region in enumerate(regions):\n",
    "    region_data = df_correlation[df_correlation[\"region\"] == region]\n",
    "\n",
    "    # Temperature plot (top row)\n",
    "    sns.scatterplot(\n",
    "        data=region_data,\n",
    "        x=\"temperature\",\n",
    "        y=\"price\",\n",
    "        alpha=0.7,\n",
    "        color=f\"C{i}\",\n",
    "        ax=axes[i, 0],\n",
    "    )\n",
    "    axes[i, 0].set_title(f\"{region}\")\n",
    "    axes[i, 0].set_xlabel(\"Temperature (°C)\")\n",
    "    axes[i, 0].set_ylabel(\"Price (€)\")\n",
    "\n",
    "    # Add regression line\n",
    "    sns.regplot(\n",
    "        x=\"temperature\",\n",
    "        y=\"price\",\n",
    "        data=region_data,\n",
    "        scatter=False,\n",
    "        ax=axes[i, 0],\n",
    "        color=f\"C{i}\",\n",
    "        line_kws={\"linestyle\": \"--\"},\n",
    "    )\n",
    "\n",
    "    # Precipitation plot (bottom row)\n",
    "    sns.scatterplot(\n",
    "        data=region_data,\n",
    "        x=\"precipitation\",\n",
    "        y=\"price\",\n",
    "        alpha=0.7,\n",
    "        color=f\"C{i}\",\n",
    "        ax=axes[i, 1],\n",
    "    )\n",
    "    axes[i, 1].set_title(f\"{region}\")\n",
    "    axes[i, 1].set_xlabel(\"Precipitation (mm)\")\n",
    "    axes[i, 1].set_ylabel(\"Price (€)\")\n",
    "\n",
    "    # Add regression line\n",
    "    sns.regplot(\n",
    "        x=\"precipitation\",\n",
    "        y=\"price\",\n",
    "        data=region_data,\n",
    "        scatter=False,\n",
    "        ax=axes[i, 1],\n",
    "        color=f\"C{i}\",\n",
    "        line_kws={\"linestyle\": \"--\"},\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots showing weekday effect for all regions\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "fig.suptitle(\"Weekday Effect on Ski Prices by Region\", fontsize=16)\n",
    "\n",
    "for i, region in enumerate(regions):\n",
    "    sns.boxplot(\n",
    "        data=df_correlation[df_correlation[\"region\"] == region],\n",
    "        x=\"day_of_week\",\n",
    "        y=\"price\",\n",
    "        ax=axes[i],\n",
    "        color=f\"C{i}\",\n",
    "    )\n",
    "    axes[i].set_xlabel(\"Day of Week\")\n",
    "    axes[i].set_ylabel(\"Price (€)\")\n",
    "    axes[i].set_title(f\"{region}\")\n",
    "    axes[i].set_xticks(range(7))\n",
    "    axes[i].set_xticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Saving Processed Data\n",
    "\n",
    "Finally, let's save our processed dataset for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "df_merged.to_csv(\"01_ski-prices.csv\", index=False)\n",
    "print(\"Processed data saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this analysis, we explored ski resort pricing data along with weather conditions. Key findings include:\n",
    "\n",
    "1. Trends over time for different resorts\n",
    "2. Correlations between temperature, precipitation, and resort prices\n",
    "3. Day-of-week patterns in pricing\n",
    "4. Regional differences in pricing strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "djpyworkshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
